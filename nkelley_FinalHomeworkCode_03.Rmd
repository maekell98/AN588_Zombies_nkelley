---
title: "nkelley_FinalHomeworkCode_03"
author: "Natalia Kelley"
output:
  html_document:
    toc: TRUE
    toc_depth: 3
    toc_float: TRUE
---

```{r load packages}
library(curl)
library(ggplot2)
library(tidyverse)
library("reshape2")
```

# Part One

Calculate the population mean and standard deviation for each quantitative random variable (height, weight, age, number of zombies killed, and years of education). NOTE: You will not want to use the built in var() and sd() commands as these are for samples.

```{r question 1}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
#creates data frame from raw csv file

s <- select(d, "height", "weight", "age", "zombies_killed", "years_of_education")

#select function creates new data frame with only the columns selected from data frame d 

ssq <- function(x) {sum((x-mean(x))^2)} #Function to calculate the sum of squares.
pop_var <- function(x) {ssq(x)/length(x)} #Function to calculate the variance of the population (note it is divided by "n" instead of by "n-1")
pop_sd <- function(x) {sqrt(pop_var(x))} #Function to calculate the standard deviation of the population.

#the above population functions courtesy of Miguel. I believe he calculated sd better than I did (because I just used regular sd() at first), so I inserted his function for sd into my cbind function below.

cbind(mean = apply(s, 2, mean), sd = apply(s, 2, pop_sd))

#combines data frames with shared column headers. x and y (in this case mean and sd) specify the new column headers. The new row headers are the old column headers. I inserted the apply functions as the data to populate the x/y columns with apply(s, 2, mean) extracting the means of the columns (1=rows, 2=columns) from df s. The same for apply(s, 2, sd) except this extracted the sd. 
```

**Result:**
                        mean        sd
height              67.63010  4.307970
weight             143.90748 18.391857
age                 20.04696  2.963583
zombies_killed       2.99200  1.747551
years_of_education   2.99600  1.675704

# Part Two 

Use {ggplot} to make boxplots of each of these variables by gender.

```{r boxplots by gender}

f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
#creates data frame from raw csv file

GenderPlotHeight = ggplot(d, aes(x = gender, y = height)) + geom_boxplot() 
GenderPlotHeight
#ggplot with data pulled from data frame d, with x representing gender and y representing height organized into a geom_boxplot() 

GenderPlotWeight <- ggplot(d, aes(x = gender, y = weight)) + geom_boxplot() 
GenderPlotWeight

GenderPlotAge <- ggplot(d, aes(x = gender, y = age)) + geom_boxplot() 
GenderPlotAge

GenderPlotZombiesKilled <- ggplot(d, aes(x = gender, y = zombies_killed)) + geom_boxplot() 
GenderPlotZombiesKilled

GenderPlotYearsEducation <- ggplot(d, aes(x = gender, y = years_of_education)) + geom_boxplot() 
GenderPlotYearsEducation

```

# Part Three

Use {ggplot} to make scatterplots of height and weight in relation to age. Do these variables seem to be related? In what way?

```{r scatterplots}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
#creates data frame from raw csv file

AgeVsHeight <- ggplot(d, aes(x = age, y = height)) + geom_point() 
AgeVsHeight

#geom_point() is used to generate a scatter plot. With ggplot, you specify where the data is drawn from by using the ggplot function and then + ....() to specify how that data should be plotted. 

AgeVsWeight <- ggplot(d, aes(x = age, y = weight)) + geom_point() 
AgeVsWeight
```
There appears to be a positive correlation between age and height as well as between age and weight. 


# Part Four

Using histograms and Q-Q plots, check whether the quantitative variables seem to be drawn from a normal distribution. Which seem to be and which do not (hint: not all are drawn from the normal distribution)? For those that are not normal, can you determine from which common distribution they are drawn?

```{r histograms and Q-Q plots}

f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
#creates data frame from raw csv file

s <- select(d, "height", "weight", "age", "zombies_killed", "years_of_education")

#c <- ggplot(mpg, aes(hwy)); c2 <- ggplot(mpg) 
#use c for histogram, c2 for qq plot
#c + geom_histogram(binwidth = 5) x, y, alpha, color, fill, linetype, size, weigh
#c2 + geom_qq(aes(sample = hwy)) x, y, alpha, color, fill, linetype, size, weight


ggplot(s, aes(x = age)) + geom_histogram()

ggplot(s, aes(sample = age)) + geom_qq()

#age

ggplot(s, aes(x = height)) + geom_histogram()

ggplot(s, aes(sample = height)) + geom_qq()

#height

ggplot(s, aes(x = weight)) + geom_histogram()

ggplot(s, aes(sample = weight)) + geom_qq()

#weight

ggplot(s, aes(x = zombies_killed)) + geom_histogram()

ggplot(s, aes(sample = zombies_killed)) + geom_qq()

#number of zombies killed

ggplot(s, aes(x = years_of_education)) + geom_histogram()

ggplot(s, aes(sample=years_of_education)) + geom_qq()

#years of education

hist(rpois(1000, 3), probability = T)
#distribution -- looks like Poisson
```

Age, height, and weight appear to be normally distributed. However, number of zombies killed and years of education appear to be skewed due to their curved qqplots and histograms which both appear to be somewhat skewed right. 

Zombies killed and years of education appear to be drawn from the Poisson distribution, which makes sense since Poisson distributions are used to show the probability of an event occurring over a specific period of time. 


# Part Five

Now use the sample() function to sample ONE subset of 30 zombie survivors (without replacement) from this population and calculate the mean and sample standard deviation for each variable. Also estimate the standard error for each variable, and construct the 95% confidence interval for each mean. Note that for the variables that are not drawn from the normal distribution, you may need to base your estimate of the CIs on slightly different code than for the normalâ€¦

package sciplot has standard error in it

```{r sample subset with mean and sd}

f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
#creates data frame from raw csv file

set.seed(30)
sample <- d[sample(nrow(d), 30, replace = FALSE), ]

s <- select(sample, "height", "weight", "age", "zombies_killed", "years_of_education")


#**Normally Distributed CI's:**

n <- select(sample, "height", "weight", "age")

nstat <- cbind(mean = apply(n, 2, mean), 
               sd = apply(n, 2, pop_sd), 
               se = (apply(n, 2, pop_sd))/sqrt(length(n)), 
               lower = (apply(n, 2, mean)) - qnorm(1 - 0.05/2) * (apply(n, 2, pop_sd))/sqrt(length(n)), 
               upper = (apply(n, 2, mean)) + qnorm(1 - 0.05/2) * (apply(n, 2, pop_sd))/sqrt(length(n)))
nstat

library(boot)

#**Abnormally Distributed CI's:**

a <- select(sample, "zombies_killed", "years_of_education")

#for zombies killed:

zkset <- NULL  # sets up a dummy variable to hold our 10000 simulations
n <- 30
for (i in 1:1000) {
    zkset[i] <- mean(sample(a$zombies_killed, n, replace = TRUE))
}

quantile(zkset, c(0.025, 0.975))

#for years of education:
yeset <- NULL  # sets up a dummy variable to hold our 10000 simulations
n <- 30
for (i in 1:1000) {
    yeset[i] <- mean(sample(a$years_of_education, n, replace = TRUE))
}

quantile(yeset, c(0.025, 0.975))

```
**Normally Distributed Data Stats:**
            mean        sd        se     lower     upper
height  67.00077  5.117727  2.954721  61.20962  72.79191
weight 144.53039 19.477669 11.245438 122.48974 166.57104
age     19.37349  3.269286  1.887523  15.67401  23.07296

**Non-normally Distributed Data Stats:**
zombies killed:
mean: 3.233333
sd: 2.028815
se: 0.359589
CI: (2.599167, 3.966667)

years of education:
mean: 2.833333
sd: 0.9855275
se: 0.1752246
CI: (2.466667, 3.166667)

I used bootstrapping to calculate these intervals.


# Part Six

Now draw 99 more random samples of 30 zombie apocalypse survivors, and calculate the mean for each variable for each of these samples. Together with the first sample you drew, you now have a set of 100 means for each variable (each based on 30 observations), which constitutes a sampling distribution for each variable. What are the means and standard deviations of this distribution of means for each variable? How do the standard deviations of means compare to the standard errors estimated in [5]? What do these sampling distributions look like (a graph might help here)? Are they normally distributed? What about for those variables that you concluded were not originally drawn from a normal distribution?

```{r more random samples}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)


set.seed(30)

#height:

height <- NULL

for(i in 1:100) {
  
  height[i] <- mean(sample(d$height, size=30, replace=FALSE, prob = NULL))
  
}

sheight <- height[] 
sheight

hist(sheight)

mean(sheight)
sd(sheight)

#weight:

weight <- NULL

for(i in 1:100) {
  
  weight[i] <- mean(sample(d$weight, size=30, replace=FALSE, prob = NULL))
  
}

sweight <- weight[] 
sweight

hist(sweight)

mean(sweight)
sd(sweight)

#age:

age <- NULL

for(i in 1:100) {
  
  age[i] <- mean(sample(d$age, size=30, replace=FALSE, prob = NULL))
  
}

sage <- age[] 
sage

hist(sage)

mean(sage)
sd(sage)

#zombies killed

zk <- NULL

for(i in 1:100) {
  
  zk[i] <- mean(sample(d$zombies_killed, size=30, replace=FALSE, prob = NULL))
  
}

szk <- zk[] 
szk

hist(szk)

mean(szk)
sd(szk)

#years of education

ye <- NULL

for(i in 1:100) {
  
  ye[i] <- mean(sample(d$years_of_education, size=30, replace=FALSE, prob = NULL))
  
}

sye <- ye[] 
sye

hist(sye)

mean(sye)
sd(sye)

```
The histograms look more normal, especially for the distributions that originally looked skewed.

Bootstrapping allows you to analyze non-normal data with parametric analysis. 


# Challenges

1. I had trouble formatting functions to actually pull the data I wanted.

2. I could figure out how to get data one calculation at a time, but doing this more efficiently and getting data into nice data frames from scratch was tricky/not successful. 

3. I had a lot of trouble figuring out how to use bootstrapping functions. I feel like this stemmed from a desire to use a function with "bootstrap" in the name that would just spit the answers out, which resulted in lots of difficulty with syntax and understanding what I was doing. When I just broke it down to the for loop, I had a much better idea of what bootstrapping even was. Obviously, this was in the modules, but I didn't really understand it until I was doing it for the homework.   