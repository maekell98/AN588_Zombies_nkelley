---
title: "mrubiog2000_PeerCommentary_maekell98"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r install packages/data}

install.packages("tidyverse")

install.packages("ggplot2")

library(curl)

library(ggplot2)

library(tidyverse)

install.packages("reshape2")
library("reshape2")
```

1. Calculate the population mean and standard deviation for each quantitative random variable (height, weight, age, number of zombies killed, and years of education). NOTE: You will not want to use the built in var() and sd() commands as these are for samples.

```{r question 1}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
#creates data frame from raw csv file

s <- select(d, "height", "weight", "age", "zombies_killed", "years_of_education")

#select function creates new data frame with only the columns selected from data frame d 

cbind(mean = apply(s, 2, mean), sd = apply(s, 2, sd))

#combines data frames with shared column headers. x and y (in this case mean and sd) specify the new column headers. The new row headers are the old column headers. I inserted the apply functions as the data to populate the x/y columns with apply(s, 2, mean) extracting the means of the columns (1=rows, 2=columns) from df s. The same for apply(s, 2, sd) except this extracted the sd. 
```
**Result:**
                        mean        sd
height              67.63010  4.310126
weight             143.90748 18.401060
age                 20.04696  2.965066
zombies_killed       2.99200  1.748426
years_of_education   2.99600  1.676543

```{r}
##Miguel: Awesome! I really liked how you used the "select" function to only work with the variables you wanted form the data frame. Besides, you did a good job using the functions "cbind" and "apply" to give a clear and visual answer to the question.

##Miguel: I think you cannot use here the command "sd" as we want to obtain the standard deviation from the population insead of from a sample. The "sd" command uses "n-1" in the denominator (one degree of freedom) and we only apply degrees of freedom when talking about a sample. When studying the population that is not necessary becaurse we are seeing every possible individual).
##You can try to set functions to calculate the sum of squares -> population variance and finally the population standar deviation as we did in Module 07. You can check my code too if you want :)
```



2. Use {ggplot} to make boxplots of each of these variables by gender.

```{r boxplots by gender}

f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
#creates data frame from raw csv file

GenderPlotHeight = ggplot(d, aes(x = gender, y = height)) + geom_boxplot() 
GenderPlotHeight
#ggplot with data pulled from data frame d, with x representing gender and y representing height organized into a geom_boxplot() 

GenderPlotWeight <- ggplot(d, aes(x = gender, y = weight)) + geom_boxplot() 
GenderPlotWeight

GenderPlotAge <- ggplot(d, aes(x = gender, y = age)) + geom_boxplot() 
GenderPlotAge

GenderPlotZombiesKilled <- ggplot(d, aes(x = gender, y = zombies_killed)) + geom_boxplot() 
GenderPlotZombiesKilled

GenderPlotYearsEducation <- ggplot(d, aes(x = gender, y = years_of_education)) + geom_boxplot() 
GenderPlotYearsEducation

```

```{r}
##Miguel: Good job! You can try to use the function "grid.arrange("name of the plots")" to be able to see the 5 plots at the same time, so you can make visual comparisons easily. You will need to use "library(gridExtra)" before.
```


3. Use {ggplot} to make scatterplots of height and weight in relation to age. Do these variables seem to be related? In what way?

```{r scatterplots}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
#creates data frame from raw csv file

AgeVsHeight <- ggplot(d, aes(x = age, y = height)) + geom_point() 
AgeVsHeight

#geom_point() is used to generate a scatter plot. With ggplot, you specify where the data is drawn from by using the ggplot function and then + ....() to specify how that data should be plotted. 

AgeVsWeight <- ggplot(d, aes(x = age, y = weight)) + geom_point() 
AgeVsWeight
```
There appears to be a positive correlation between age and height as well as between age and weight. 

```{r}
##Miguel: Good job. You can try here too the "grid.arrange" function if you want.
```


4. Using histograms and Q-Q plots, check whether the quantitative variables seem to be drawn from a normal distribution. Which seem to be and which do not (hint: not all are drawn from the normal distribution)? For those that are not normal, can you determine from which common distribution they are drawn?

```{r histograms and Q-Q plots}

f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
#creates data frame from raw csv file

s <- select(d, "height", "weight", "age", "zombies_killed", "years_of_education")

#c <- ggplot(mpg, aes(hwy)); c2 <- ggplot(mpg) 
#use c for histogram, c2 for qq plot
#c + geom_histogram(binwidth = 5) x, y, alpha, color, fill, linetype, size, weigh
#c2 + geom_qq(aes(sample = hwy)) x, y, alpha, color, fill, linetype, size, weight

ggplot(s, aes(x = age)) + geom_histogram()

ggplot(s, aes(sample = age)) + geom_qq()

#age

ggplot(s, aes(x = height)) + geom_histogram()

ggplot(s, aes(sample = height)) + geom_qq()

#height

ggplot(s, aes(x = weight)) + geom_histogram()

ggplot(s, aes(sample = weight)) + geom_qq()

#weight

ggplot(s, aes(x = zombies_killed)) + geom_histogram()

ggplot(s, aes(sample = zombies_killed)) + geom_qq()

#number of zombies killed

ggplot(s, aes(x = years_of_education)) + geom_histogram()

ggplot(s, aes(sample=years_of_education)) + geom_qq()

#years of education
```

Age, height, and weight appear to be normally distributed. However, number of zombies killed and years of education appear to be skewed due to their curved qqplots and histograms which both appear to be somewhat skewed right. 


```{r}
##Miguel: Nice! For this one I used the "hist()" function from basic R because I think it is easier to visualize each bar from the histogram (and the question does not specify to use ggplot).
```


5. Now use the sample() function to sample ONE subset of 30 zombie survivors (without replacement) from this population and calculate the mean and sample standard deviation for each variable. Also estimate the standard error for each variable, and construct the 95% confidence interval for each mean. Note that for the variables that are not drawn from the normal distribution, you may need to base your estimate of the CIs on slightly different code than for the normalâ€¦

```{r sample subset with mean and sd}

f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
#creates data frame from raw csv file

set.seed(30)
sample <- d[sample(nrow(d), 30, replace = FALSE), ]

s <- select(sample, "height", "weight", "age", "zombies_killed", "years_of_education")


#**Normally Distributed CI's:**

n <- select(sample, "height", "weight", "age")

nstat <- cbind(mean = apply(n, 2, mean), 
               sd = apply(n, 2, sd), 
               se = (apply(n, 2, sd))/sqrt(length(n)), 
               lower = (apply(n, 2, mean)) - qnorm(1 - 0.05/2) * (apply(n, 2, sd))/sqrt(length(n)), 
               upper = (apply(n, 2, mean)) + qnorm(1 - 0.05/2) * (apply(n, 2, sd))/sqrt(length(n)))
nstat

library(boot)

#**Abnormally Distributed CI's:**

a <- select(sample, "zombies_killed", "years_of_education")

#for zombies killed:
B = 1000
n = nrow(a)
boot.samples = matrix(sample(a$zombies_killed, size = B * n, replace = TRUE),
B, n)
zk.mean = with(a, mean(zombies_killed))
zk.mean
zk.sd = with(a, sd(zombies_killed))
zk.sd
boot.statistics = apply(boot.samples, 1, mean)
zk.se = sd(boot.statistics)
zk.se
me = ceiling(10 * 2 * zk.se)/10
round(zk.mean, 1) + c(-1, 1) * me

#for years of education:
boot.samples = matrix(sample(a$years_of_education, size = B * n, replace = TRUE),
B, n)
zk.mean = with(a, mean(years_of_education))
zk.mean
zk.sd = with(a, sd(years_of_education))
zk.sd
boot.statistics = apply(boot.samples, 1, mean)
zk.se = sd(boot.statistics)
zk.se
me = ceiling(10 * 2 * zk.se)/10
round(zk.mean, 1) + c(-1, 1) * me

```
**Normally Distributed Data Stats:**
            mean        sd        se     lower     upper
height  67.00077  5.205216  3.005233  61.11062  72.89092
weight 144.53039 19.810645 11.437681 122.11295 166.94783
age     19.37349  3.325175  1.919791  15.61077  23.13621

**Non-normally Distributed Data Stats:**
zombies killed:
mean: 3.233333
sd: 2.028815
se: 0.359589
CI: (2.4, 4.0)

years of education:
mean: 2.833333
sd: 0.9855275
se: 0.1752246
CI: (2.4, 3.2)


6. Now draw 99 more random samples of 30 zombie apocalypse survivors, and calculate the mean for each variable for each of these samples. Together with the first sample you drew, you now have a set of 100 means for each variable (each based on 30 observations), which constitutes a sampling distribution for each variable. What are the means and standard deviations of this distribution of means for each variable? How do the standard deviations of means compare to the standard errors estimated in [5]? What do these sampling distributions look like (a graph might help here)? Are they normally distributed? What about for those variables that you concluded were not originally drawn from a normal distribution?

```{r more random samples}
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/zombies.csv")

d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)


set.seed(30)

#height:

height <- NULL

for(i in 1:99) {
  
  height[i] <- mean(sample(d$height, size=30, replace=FALSE, prob = NULL))
  
}

sheight <- height[] 
sheight

hist(sheight)

mean(sheight)
sd(sheight)

#weight:

weight <- NULL

for(i in 1:99) {
  
  weight[i] <- mean(sample(d$weight, size=30, replace=FALSE, prob = NULL))
  
}

sweight <- weight[] 
sweight

hist(sweight)

mean(sweight)
sd(sweight)

#age:

age <- NULL

for(i in 1:99) {
  
  age[i] <- mean(sample(d$age, size=30, replace=FALSE, prob = NULL))
  
}

sage <- age[] 
sage

hist(sage)

mean(sage)
sd(sage)

#zombies killed

zk <- NULL

for(i in 1:99) {
  
  zk[i] <- mean(sample(d$zombies_killed, size=30, replace=FALSE, prob = NULL))
  
}

szk <- zk[] 
szk

hist(szk)

mean(szk)
sd(szk)

#years of education

ye <- NULL

for(i in 1:99) {
  
  ye[i] <- mean(sample(d$years_of_education, size=30, replace=FALSE, prob = NULL))
  
}

sye <- ye[] 
sye

hist(sye)

mean(sye)
sd(sye)

```
The histograms look more normal, especially for the distributions that originally looked skewed.


Challenges:
1. I had trouble formatting functions to actually pull the data I wanted.

2. I could figure out how to get data one calculation at a time, but doing this more efficiently and getting data into nice data frames from scratch was tricky/not successful. 

3. I had a lot of trouble figuring out how to use bootstrapping functions.  